{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation Visualisations for KNN Classifier\n",
        "\n",
        "This section provides a detailed explanation of various visualisations that can be used to evaluate and improve the performance of a K-Nearest Neighbours (KNN) model. These plots help us detect overfitting, underfitting, performance differences across classes, and optimal hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Accuracy vs. K Plot\n",
        "\n",
        "**Purpose:**  \n",
        "This plot helps determine the optimal number of neighbours (`k`) for the KNN algorithm. It shows how training and validation accuracy change as `k` increases.\n",
        "\n",
        "**Interpretation:**  \n",
        "- If accuracy is low for all `k`, the model might be underfitting.\n",
        "- If training accuracy is high and validation is low for small `k`, the model may be overfitting.\n",
        "- Choose the `k` where the validation accuracy is high and stable.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Learning Curve\n",
        "\n",
        "**Purpose:**  \n",
        "The learning curve plots training and validation accuracy against the number of training examples.\n",
        "\n",
        "**Interpretation:**\n",
        "- If both training and validation scores are low → **underfitting**\n",
        "- If training is high but validation is low → **overfitting**\n",
        "- If both scores are high and close → **good generalisation**\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Confusion Matrix with Precision, Recall, F1 Score\n",
        "\n",
        "**Purpose:**  \n",
        "Displays how well the model performs per class by showing actual vs predicted labels. It is useful for multi-class classification problems.\n",
        "\n",
        "**Additional Metrics Shown:**\n",
        "- **Accuracy** – Overall correct predictions\n",
        "- **Precision** – Correct positive predictions / Total predicted positives\n",
        "- **Recall** – Correct positive predictions / Total actual positives\n",
        "- **F1 Score** – Harmonic mean of precision and recall\n",
        "\n",
        "---\n",
        "\n",
        "## 4. ROC Curve (One-vs-Rest)\n",
        "\n",
        "**Purpose:**  \n",
        "Useful in binary or multiclass classification to evaluate trade-offs between true positive rate and false positive rate for each class.\n",
        "\n",
        "**Interpretation:**\n",
        "- AUC (Area Under Curve) close to 1 = good classifier.\n",
        "- AUC close to 0.5 = no better than random guessing.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Decision Boundary (2D Visualisation)\n",
        "\n",
        "**Purpose:**  \n",
        "Helps visualise how the KNN classifier separates different classes in a 2D feature space.\n",
        "\n",
        "**Interpretation:**\n",
        "- Clear and smooth boundaries with accurate test classification indicate a good fit.\n",
        "- Irregular and noisy boundaries may indicate overfitting.\n",
        "\n",
        "*Note: This is only possible when using two features, or after dimensionality reduction (e.g., PCA).*\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Error Analysis Plot (Correct vs Incorrect Predictions)\n",
        "\n",
        "**Purpose:**  \n",
        "Visualises how many predictions were correct or incorrect for each class.\n",
        "\n",
        "**Interpretation:**\n",
        "- Helps identify which classes the model struggles to classify correctly.\n",
        "- Useful for identifying class imbalance or confusion between similar classes.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary of Visualisations\n",
        "\n",
        "| Visualisation               | Purpose                                      |\n",
        "|----------------------------|----------------------------------------------|\n",
        "| Accuracy vs. K             | Choose the optimal number of neighbours      |\n",
        "| Learning Curve             | Diagnose underfitting or overfitting         |\n",
        "| Confusion Matrix + Metrics | Evaluate class-level prediction performance  |\n",
        "| ROC / PR Curve             | Assess model on class imbalance              |\n",
        "| Decision Boundary (2D)     | Visualise how KNN separates classes          |\n",
        "| Error Plot                 | Understand per-class error distribution      |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "pe9LOEi3YFMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "vYbCji9JYdjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn matplotlib seaborn --quiet"
      ],
      "metadata": {
        "id": "NhrHAzbUjlDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overall Code for model training"
      ],
      "metadata": {
        "id": "hJrNCvunYgnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
        "\n"
      ],
      "metadata": {
        "id": "jn4GjJvgVyr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Import libraries ---\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.metrics import accuracy_score, classification_report, r2_score, mean_absolute_error\n",
        "\n",
        "\n",
        "\n",
        "# --- Basic cleaning ---\n",
        "df = df.dropna(subset=['PI1'])                     # drop rows with missing target\n",
        "df = df.dropna(axis=1, how='all')                  # remove empty columns\n",
        "df = df.fillna(method='ffill')                     # simple forward fill for missing values\n",
        "\n",
        "# --- Encode categorical variables ---\n",
        "le = LabelEncoder()\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "# --- Define features (X) and target (y) ---\n",
        "y = df['PI1']\n",
        "X = df.drop(columns=['PI1'])\n",
        "\n",
        "# --- Split data ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- Decide automatically: classification or regression ---\n",
        "if y.nunique() < 10 and y.dtype != 'float':   # likely classification\n",
        "    model = KNeighborsClassifier(n_neighbors=3)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"✅ KNN Classification Results\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "else:                                         # regression\n",
        "    model = KNeighborsRegressor(n_neighbors=3)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"✅ KNN Regression Results\")\n",
        "    print(\"R²:\", r2_score(y_test, y_pred))\n",
        "    print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "\n",
        "print(\"\\nModel training complete ✔️\")\n"
      ],
      "metadata": {
        "id": "GoozA09chEgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix, and learning curve"
      ],
      "metadata": {
        "id": "5wVZJTTnYqlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, ConfusionMatrixDisplay,\n",
        "    classification_report, accuracy_score\n",
        ")\n",
        "\n",
        "# Ensure model exists\n",
        "knn = model   # or whichever variable name you used for your trained classifier\n",
        "\n",
        "# --- Confusion Matrix ---\n",
        "labels = np.unique(y)\n",
        "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Classification Report & Accuracy ---\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, labels=labels, zero_division=0))\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "# --- Learning Curve ---\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    estimator=knn,\n",
        "    X=X, y=y,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "    n_jobs=-1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', label='Training score')\n",
        "plt.plot(train_sizes, test_scores_mean, 'o-', label='Cross-validation score')\n",
        "plt.xlabel('Training examples')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Curve — KNN Classifier')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hTh-bBhFYpb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test if model fit is optimal"
      ],
      "metadata": {
        "id": "dQ1uz423Y0IC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model fit status based on learning curve\n",
        "def evaluate_fit(train_scores_mean, test_scores_mean, threshold_gap=0.05, threshold_low=0.75):\n",
        "    final_train = train_scores_mean[-1]\n",
        "    final_val = test_scores_mean[-1]\n",
        "    gap = final_train - final_val\n",
        "\n",
        "    print(\"\\n--- Fit Evaluation ---\")\n",
        "    print(f\"Final Training Accuracy: {final_train:.4f}\")\n",
        "    print(f\"Final Validation Accuracy: {final_val:.4f}\")\n",
        "    print(f\"Train-Validation Gap: {gap:.4f}\")\n",
        "\n",
        "    if final_train < threshold_low and final_val < threshold_low:\n",
        "        print(\"Model is likely **Underfitting**: Both training and validation accuracy are low.\")\n",
        "    elif gap > threshold_gap:\n",
        "        print(\"Model is likely **Overfitting**: Training accuracy is high, but validation accuracy drops.\")\n",
        "    else:\n",
        "        print(\"Model is likely a **Good Fit**: Training and validation accuracy are both high and close.\")\n",
        "\n",
        "\n",
        "evaluate_fit(train_scores_mean, test_scores_mean)\n"
      ],
      "metadata": {
        "id": "S1xCZUqfWHgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find best value for k"
      ],
      "metadata": {
        "id": "z43vD50dY34d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try different k values\n",
        "k_range = range(1, 21)\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "for k in k_range:\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X_train, y_train)\n",
        "    train_acc.append(model.score(X_train, y_train))\n",
        "    test_acc.append(model.score(X_test, y_test))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_range, train_acc, label='Training Accuracy', marker='o')\n",
        "plt.plot(k_range, test_acc, label='Validation Accuracy', marker='x')\n",
        "plt.xlabel('Number of Neighbors (k)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs. K Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuHUPJAXWcHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determine ROC curve"
      ],
      "metadata": {
        "id": "g_tyzMAaY8JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imbalanced datasets\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "\n",
        "y_bin = label_binarize(y, classes=np.unique(y))\n",
        "n_classes = y_bin.shape[1]\n",
        "\n",
        "\n",
        "classifier = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=3))\n",
        "X_train, X_test, y_train_bin, y_test_bin = train_test_split(X, y_bin, test_size=0.3, random_state=42)\n",
        "classifier.fit(X_train, y_train_bin)\n",
        "y_score = classifier.predict_proba(X_test)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title(\"ROC Curves for Each Class (One-vs-Rest)\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PDekjl6-XG8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Illustrate the feature space as a 2D representation"
      ],
      "metadata": {
        "id": "40hBNyhKZAC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# --- Assume you already have df and target column PI1 (categorical) ---\n",
        "# If your PI1 is numeric/continuous, use a regressor instead (decision boundaries below are for classification).\n",
        "\n",
        "# Build X, y from your DataFrame\n",
        "# Choose two numeric columns to visualise (edit these names as you like):\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "assert 'PI1' in df.columns, \"PI1 must be present in df\"\n",
        "X = df[num_cols].drop(columns=['PI1'], errors='ignore')\n",
        "y = df['PI1']\n",
        "\n",
        "# Keep only the first two numeric features for 2D plot (or choose by name)\n",
        "if len(X.columns) < 2:\n",
        "    raise ValueError(\"Need at least two numeric features to plot a 2D decision boundary.\")\n",
        "feat1, feat2 = X.columns[:2]\n",
        "X_vis_df = X[[feat1, feat2]].copy()\n",
        "\n",
        "# Encode y if needed\n",
        "if y.dtype == 'O' or not np.issubdtype(y.dtype, np.number):\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y.astype(str))\n",
        "    class_names = le.classes_\n",
        "else:\n",
        "    # ensure consecutive ints for plotting\n",
        "    classes, y_enc = np.unique(y, return_inverse=True)\n",
        "    class_names = classes.astype(str)\n",
        "\n",
        "# Train/test split\n",
        "X_train_vis, X_test_vis, y_train_vis, y_test_vis = train_test_split(\n",
        "    X_vis_df.values, y_enc, test_size=0.3, random_state=42, stratify=y_enc\n",
        ")\n",
        "\n",
        "# Fit KNN\n",
        "knn_vis = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_vis.fit(X_train_vis, y_train_vis)\n",
        "\n",
        "# Mesh grid\n",
        "h = 0.02\n",
        "x_min, x_max = X_vis_df[feat1].min() - 1, X_vis_df[feat1].max() + 1\n",
        "y_min, y_max = X_vis_df[feat2].min() - 1, X_vis_df[feat2].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "Z = knn_vis.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "# Colormaps sized to number of classes\n",
        "n_classes = len(np.unique(y_enc))\n",
        "# light background colors\n",
        "light_colors = ['#FFEEEE','#EEFFEE','#EEEEFF','#FFF0CC','#E6E6FA','#E0FFFF','#FFE4E1','#F0FFF0','#FFFACD']\n",
        "# bold point colors\n",
        "bold_colors  = ['#FF3333','#33AA33','#3333FF','#FF9900','#800080','#008B8B','#CD5C5C','#228B22','#DAA520']\n",
        "cmap_light = ListedColormap(light_colors[:n_classes])\n",
        "cmap_bold  = ListedColormap(bold_colors[:n_classes])\n",
        "\n",
        "plt.figure(figsize=(9, 7))\n",
        "plt.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.8)\n",
        "\n",
        "# Plot train/test points\n",
        "sc1 = plt.scatter(X_train_vis[:, 0], X_train_vis[:, 1], c=y_train_vis, cmap=cmap_bold,\n",
        "                  edgecolor='k', marker='o', label='Train', alpha=0.9)\n",
        "sc2 = plt.scatter(X_test_vis[:, 0], X_test_vis[:, 1], c=y_test_vis, cmap=cmap_bold,\n",
        "                  edgecolor='k', marker='^', label='Test', alpha=0.9)\n",
        "\n",
        "plt.xlabel(feat1)\n",
        "plt.ylabel(feat2)\n",
        "plt.title(\"2D Decision Boundary — KNN Classifier\")\n",
        "\n",
        "# Custom legend with class labels\n",
        "handles, _ = sc1.legend_elements(prop=\"colors\", alpha=0.9)\n",
        "class_legend = plt.legend(handles, class_names, title=\"Classes\", loc=\"upper right\")\n",
        "plt.gca().add_artist(class_legend)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fFbcTopcXKnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "error_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "error_df['Correct'] = error_df['Actual'] == error_df['Predicted']\n",
        "\n",
        "sns.countplot(x='Actual', hue='Correct', data=error_df)\n",
        "plt.title(\"Correct vs Incorrect Predictions by Class\")\n",
        "plt.xlabel(\"True Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend(title='Prediction Correct')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P2coJAugXZA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMKnHLwNXdGW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}